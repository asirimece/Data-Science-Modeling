# Data Science Modeling — Statistical Learning and Inference

This repository contains practical data science projects developed in the context of an academic *Foundations of Data Science* module. The work focuses on core statistical modeling techniques, supervised learning, and principled evaluation of model behavior across different data regimes.

The emphasis is on **interpretable models**, **bias–variance trade-offs**, and **statistical assumptions**, rather than black-box performance.

---

## Scope & Technical Coverage

The projects in this repository cover the following areas:

### 1. Linear Models and Regularization
- Linear regression for continuous target prediction
- Analysis of overfitting and underfitting
- Feature scaling and polynomial basis expansion
- Regularization using Ridge and Lasso penalties
- Model evaluation via cross-validation and error metrics
- Interpretation of feature importance and interactions

### 2. Generative vs. Discriminative Classification
- Naïve Bayes classifiers with distribution-specific likelihoods
- Logistic regression as a discriminative baseline
- Handling continuous, binary, and categorical features
- Comparative evaluation across multiple datasets and sample sizes
- Analysis of accuracy and model assumptions

---

## Implementation Details

All models and experiments are implemented in **Python**, using standard scientific and machine-learning libraries. The repository emphasizes:

- Explicit model formulations and assumptions  
- Careful preprocessing and feature encoding  
- Quantitative evaluation and comparison  
- Reproducible experimental setups  

---

## Repository Structure

```text
.
├── linear_models/
│   └── linear_regression_regularization.ipynb
│
├── generative_vs_discriminative/
│   └── naive_bayes_vs_logistic_regression.ipynb
│
├── README.md
└── requirements.txt
```

---

## Technologies

- Python
- NumPy, Pandas
- Matplotlib
- SciPy
- scikit-learn

---

